项目一般由模块组成, 它能够满足普通用户的直接使用需求，例如航班延误预测应用, 图片风格迁移应用, 兰花分类项目等。 你可以 [平台功能教程》](https://momodel.cn/classroom/class/5c5696cd1afd9458d456bf54?activeKey=section)，选择`开发和部署一个应用(APP)`，来按照教程中的`.ipynb`文件指引边学边做，通过调用别人已经部署的模块(Module)，开发和部署一个应用。

## 1．**项目的构建流程**

项目支持交互式线上数据模型开发、训练与部署。

<video src="http://files.momodel.cn/mo.mp4" controls="controls" poster="http://mo-imgs.momodel.cn/HomePage/cover.png" style="width: 100%;"></video>

开发机器学习算法大致分三步。首先需要`构建数据集`，这是算法建立的基础。然后需要进行数据挖掘和分析，提取出待训练的特征，`建立模型`并训练。算法完成之后`组装成应用`，进行部署就可以让别人调用了。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps212.png) 

#### (1) **第一步，构建数据集**

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps213.png) 

#### (2) **第二步，开发模块**

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps214.png) 

#### (3) **第三步，组装应用**

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps215.png) 

Mo 支持模块引用和搭积木式的应用组装方式。初阶开发者无需掌握所有开发步骤，可以直接调用平台已有的公开模块或者导入 GitHub 项目资源，写相对少量的代码即可完成一款人工智能应用。平台机制和配套环境简化了开发过程，在一定程度上降低了开发难度。我们希望机器学习初学者不会“望而生畏”，而是能怀着对代码的热情和不断进步的成就感爱上人工智能算法。

## 2．**新建项目**

顶部导航栏的「项目」模块展示所有公开项目，支持学生新建项目进行实训，支持交互式线上数据模型开发、训练与部署等，点击【新建项目】按钮创建项目。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps216.jpg) 

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps217.jpg)![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps218.jpg) 

项目新建成功，进入Notebook开发页面进行代码编程、模型训练等项目实战。

打开`coding_here.ipynb`或新建一个`notebook`。

#### (1) 开发环境(Notebook)

Notebook 是 Mo 为开发者提供的类IDE开发环境，内嵌 JupyterLab。无论你想开发完整的应用还是组装已封装好的算法模块，都可以跳过繁琐的步骤，使用 Notebook 直接上手。

![](https://imgbed.momodel.cn/jianjie3.png)

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps219.jpg)

 

#### (2) **调用他人发布公开的模块**

在 Mo 的 Notebook 中，我们可以轻松的在我们自己的代码中，插入别人已经编写好的模块 (Module)。 插入过程按以下步骤操作：

- 首先选择想要插入模块代码的 Cell

- 打开左侧的模块图标， 搜索` iris`, 选择` iris_classifier`

- 在右侧区域打开的 Tab 中， 浏览模块详情, 选择对应的版本

- 点击 插入模块按钮， 插入模块

- 用 Notebook 界面顶上的运行按钮 <img src="https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps220.jpg" title="" alt="" width="50">， 或者` Shift+Enter`， 即可运行插入的模块

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps221.png) 

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps222.png) 

如果你得到了下图中的结果， 那么恭喜你， 成功用模块进行了一次预测

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps223.png) 

#### (3) **二次训练他人发布公开的模型模块**

如果引入的模块是可以训练的，那么我们看看如何对引入的模型模块进行二次训练.

- 选择想要插入模块代码的 Cell

- 先引入我们在本教程中需要使用到的数据集，前面的教程里我们已经学会了 [如何使用数据集](https://momodel.cn/docs/#/zh-cn/%E5%A6%82%E4%BD%95%E5%AF%BC%E5%85%A5%E5%B9%B6%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9D%97%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86) 我们搜索并插入 star-face 这个数据集. 然后`!7zx ./datasets/luxu1220-star-face/star-face.zip`来解压这个数据集的压缩文件,我们得到一个新的文件夹名为 star-face

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps224.jpg) 

- 然后, 打开左侧的模块图标，搜索` new_face_feature`, 选择 `new_face_feature`

- 在右侧区域打开的 Tab 中， 浏览模块详情， 注意查看各个参数的说明

- 在 Train 部分点击 插入代码 按钮， 插入此模块 (插入代码时, 会有一个上方会有一个“插入中”的提示框， 表示正在导入模型到项目中)

- 更改训练模块的输入参数，定义 `conf={'model_save_path': 'my_model.h5',` `'epochs': 2, 'log_dir': './', 'data_path': './star-face',` `'weight_save_path': 'my_weight.h5'}`

- 然后使用 shift+enter 快捷键或者点击上面的运行按钮运行刚才插入的几个cell

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps225.jpg) 

- 训练完成后，在左侧可以看到模型和权重文件已经被保存下来了，然后我们就可以在预测部分使用它们了.

当然, 我们这里只是一个示例，模型没有很大， 训练的 epoch 也很小，效果提升不明显. 如果你使用的模型模块是基于深度神经网络的，并且网络结构很大，那么训练时间会比较长，这时候可以创建 job 并使用 GPU 来加速训练过程，详见[这里](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B)
 

#### (4) **部署应用**

我们的功能代码在 Notebook 调试完成后就可以点击左侧的部署图标，按照指引部署应用。

**开始部署**：在 Notebook 中点击左侧栏中的部署图标，进入部署页面。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps226.jpg) 

#### (5) **插入handle函数**

handle函数是应用函数的的主函数，也是把输入和输出参数对应起来的接口函数，是部署之后其他人调用你的服务的处理方法。

选中 Cell 代码的地方，点击第一步的“插入”按钮插入handle函数。然后根据前面调试的功能代码和定义的输入输出参数，整理 handle 函数。

请按照该函数中的注释说明规范填写参数结构，这样系统就能自动提取输入输出参数，生成配置文件。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps227.jpg) 

#### (6) **准备部署文件**

整理好 handle 函数之后，点击第二步的"开始"按钮，开始准备部署时需要的文件。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps228.jpg) 

以下为操作过程，首先选择需要部署的代码。然后预览生成的代码，如果有误可以点击上一步重新选择，接下来定义输入输出参数，这里定义四个输入参数，一个输出参数。最后生成 YML 配置文件，系统会根据之前定义的 handle 函数自动识别参数。

通过这个步骤我们生成部署时需要的 Python 脚本和 YML 配置文件。 当然，你可以对生成的 `handler.py `和` app_spec.yml `文件进行进一步的编辑。

![](https://imgbed.momodel.cn/新b端帮助文档/wps/inserthandle%20(1).gif) 

#### (7) **部署应用项目**

完成所有以上步骤后，点击部署按钮进行项目部署。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps229.jpg) 

在部署的时候，系统会自动生成` handler.py `文件和 `app_spec.yml `配置文件，可选择需要发布的文件或勾选发布开发版本或正式版本，然后点击“完成”，进行部署。

#### (8) **运行已部署的项目**

在部署栏里点击`测试项目`，在网页中输入参数，运行得到输出结果，如果发现问题，可再回到项目中进行调试。![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps230.jpg) 

#### (9) **模型训练**

在此平台上你可以通过两种方式训练你的模型：在 Notebook 中直接运行、通过建立 Job 在 GPU/CPU 后台运行。前者在网页上长时间运行很容易因为各种外部因素而中断，适合短时间小模型的调试训练。后者则通过后台建立 Job 任务运行，而且可以选择 GPU 加速，适合长时间大模型的训练。

#### (10) **在 Notebook 中调试训练**

-  首先我们运行下面的 cell 代码进行必要模块的导入, 以及参数的定义, 我们在这里将每个 epoch 训练的的 batch_size 定为 128

```python
# -*- coding: utf-8 -*-

'''Trains a simple convnet on the MNIST dataset.

Gets to 99.25% test accuracy after 12 epochs
(there is still a lot of margin for parameter tuning).
16 seconds per epoch on a GPU.
'''

from __future__ import print_function
import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils
# Keras的底层库使用Theano或TensorFlow
from keras import backend as K

batch_size = 128
nb_classes = 10
nb_epoch = 12

# input image dimensions
img_rows, img_cols = 28, 28
# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
pool_size = (2, 2)
# convolution kernel size
kernel_size = (3, 3)
```

- 然后我们导入平台中mnist.npz数据集，导入数据集可参考 [如何导入并使用模块和数据集](https://momodel.cn/docs/#/zh-cn/%E5%A6%82%E4%BD%95%E5%AF%BC%E5%85%A5%E5%B9%B6%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9D%97%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86)。之后运行下方代码做一些数据预处理工作。

```python
path = './datasets/vikramtiwari-mnist-numpy-momodel/mnist.npz'
f = np.load(path)
X_train, y_train = f['x_train'], f['y_train']
X_test, y_test = f['x_test'], f['y_test']
f.close()

if K.image_data_format() == 'channels_first':
    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)
```

- **然后使用 Keras 的 Sequential 定义两层卷积网络模型**

```python
model = Sequential()

# 卷积层
# 二维卷积层对二维输入进行滑动窗卷积
# keras.layers.convolutional.Convolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)

# nb_filter：卷积核的数目,（即输出的维度）
# nb_row：卷积核的行数
# nb_col：卷积核的列数
# border_mode：边界模式，为“valid”，“same”或“full”，full需要以theano为后端
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],
                        border_mode='valid',
                        input_shape=input_shape))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))

# keras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')
# 空域信号施加最大值池化
model.add(MaxPooling2D(pool_size=pool_size))
model.add(Dropout(0.25))

# Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。
model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adadelta',
              metrics=['accuracy'])
```

- **接下来运行下面的 cell 代码进行训练**

```python
model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
          verbose=1, validation_data=(X_test, Y_test))
score = model.evaluate(X_test, Y_test, verbose=0)
print('Test score:', score[0])
print('Test accuracy:', score[1])
```

- 如果觉得训练时间太长, 可以直接点击 Notebook 顶部的 <img title="" src="https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps231.jpg" alt="" width="50"> 按钮停止程序的运行, 然后到下一小节, 把以上代码转换为py类型的文件，通过创建 Job 任务的方式训练模型。

- 最后保存训练好的模型
  
  ```python
  model.save('results/my_model.h5')
  ```
  
  **PS**: 这里有个重要的地方, 我们需要将模型保存到 results/ 文件夹下, 因为这个文件夹是 Job 与 Notebook 的共享文件夹, Job 中的训练结果只有保存到 results/ 下才能被 Notebook 读取到。

#### （11）**导出代码为Python文件**

由于加入了深层卷积网络, 此次训练过程可能会比较长, 不推荐在 Notebook 中进行长时间训练, 最好的方法是通过创建一个 CPU Job 后台训练模型。 Notebook 中的代码是在 *.ipynb 文件下的，为之后创建 Job 和部署做准备，点击 ![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps232.png) 将其转为 .py 格式的标准 python 代码。然后整理代码，完成测试后，即可进行下一步的操作。

#### (12) **创建CPU/GPU job训练模型**

点击 Python 编辑器上方的 创建 Job 任务， 选择 GPU 机器创建 Job，我们可以选择为 Job 输入一个容易辨识名字，当然也可以选择不输入，系统会默认生成。您也可以创建 Notebook 控制台 或 CPU 机器 形式的 Job ，这需要根据您训练的模型特点选择。

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps233.jpg) 

#### (13) 查看 Job 运行进程**

成功创建 Job 后, 可以在左侧 JOBS 栏中查看运行状态和运行日志，也可以在项目详情页的任务栏中查看任务。通过终止按钮可以终止训练过程。

如果训练状态显示为沙漏等待图标 ，说明当前 CPU/GPU资源被占用正在排队等待。如果显示为运行中说明 Job 正在运行。如果显示为运行失败则说明 Job 因为运行错误而中断，请检查代码。在训练过程中和训练完成后您都可以点击查看日志查看运行日志。Job 运行成功后系统会弹出弹框提示 Job 运行完成。

<img title="" src="https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps234.jpg" alt="" width="360">  <img title="" src="https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps235.jpg" alt="" width="364">

<img title="" src="https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps236.jpg" alt="" width="414"> 



#### (14) 训练指标的可视化

我们会解析你的 Job 的输出行并自动将它们转换为训练指标,并进行可视化。

你需要按照如下格式,一行一行的输出你的训练指标.

```python
print('{"metric": "<choose_metric_name>", "value": <int_or_float>}')
```

举例来说,你可以这样来记录 accuracy 的变化

```python
 print('{"metric": "accuracy", "value": 0.985}')
 # {"metric": "accuracy", "value": 0.95}
```

或者这样来记录 loss 的变化

```python
print('{{"metric": "loss", "value": {}}}'.format(loss))
# {"metric": "loss", "value": 2.2233}
```

实际上你的 value 值可以是任意的格式,但是我们目前的可视化只支持整型和浮点型数字。

我们默认使用输出的时间来作为 X-axis, 但是你也可以使用 step
或者 epoch 关键字.注意 step 和 epoch 必须是整型数值。

```python
print('{"metric": "<metric_name>", "value": <int_or_float>, "step": <int>}')
```

```python
print('{"metric": "<metric_name>", "value": <int_or_float>, "epoch": <int>}')
```

然后,可以在项目详情页的任务部分,查看可视化结果。 ![](http://imgbed.momodel.cn/5cc1a288e3067ceb154f0e46.jpg)



#### (15) 如何在 Notebook 中节省运行内存

##### 1. 通过指定合适的数据类型减少内存

当我们在读取数据文件时，例如某一列的数据范围肯定在0~255之中，那么我们可以指定为np.uint8类型，如果不手动指定的话默认为np.int64类型，这之间的差距巨大。对于浮点数如果不指定数据类型，默认的精度是float64，但是通常情况下float32，甚至float16的精度就已经足够了。所以在读取数据时指定数据类型可以节省大量内存空间。
例如我们用 pandas 读取一个 csv 文件，分别对比两者的内存占用。

当不指定数据类型时

```python
import pandas as pd
data_1 = pd.read_csv('btc.csv')

# 查看数据类型及内存占用情况
data_1.info()
```

输出信息如下：

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 3405857 entries, 0 to 3405856
Data columns (total 8 columns):
Timestamp            int64
Open                 float64
High                 float64
Low                  float64
Close                float64
Volume_(BTC)         float64
Volume_(Currency)    float64
Weighted_Price       float64
dtypes: float64(7), int64(1)
memory usage: 207.9 MB
```

当指定数据类型时

```python
# 指定数据类型
data_2 = pd.read_csv('btc.csv', dtype={'Open':np.float16, 'High':np.float16, 'Low':np.float16, 
                                       'Close':np.float16, 'Volume_(BTC)':np.float16, 
                                       'Volume_(Currency)':np.float16, 'Weighted_Price':np.float16})
data_2.info()
```

输出信息如下：

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 3405857 entries, 0 to 3405856
Data columns (total 8 columns):
Timestamp            int64
Open                 float16
High                 float16
Low                  float16
Close                float16
Volume_(BTC)         float16
Volume_(Currency)    float16
Weighted_Price       float16
dtypes: float16(7), int64(1)
memory usage: 90.9 MB
```

从以上对比可以看出，在读取数据时，只通过指定合适的数据类型，就可以减少一倍多的内存空间，是一种简单有效的方法。另外在数据处理的过程中也要及时对数据进行类型转换，减少内存。例如字符串占的内存比数字要大很多，可用数字符号代替字符串。比如我有一个叫 "country" 的列，它的值有'China'， 'USA'， 'Italy'，那么我可以用一个 map 把这三个值分别映射到1，2，3。这样也可以节省内存。

##### 2. 通过函数封装减少中间变量内存占用

Python 程序 在 Linux 或者 Mac 中，哪怕是 del 这个对象，Python 依旧不把内存还给系统，自己先占着直到进程销毁。正是由于这样的垃圾回收机制，所以会导致我们在数据处理的过程中产生大量的中间变量，浪费内存资源。一种方式是我们在数据处理过程中尽量减少赋值导致的 COPY, 修改时带上 inplace=True。如果某个中间变量一定要产生，并且我们使用后还需要释放的可以把多步数据处理过程封装到一个函数中，利用函数的内存释放机制避免产生中间变量。特别在使用 Jupyter Notebook 进行数据分析时，避免一步一步的处理方式，多采用函数封装的形式，甚至导入模块的步骤也可以封装到函数中。

以下示例对比在 Jupyter Notebook 中单步执行以下命令和封装成一个函数的内存占用情况：

单步执行时

```python
import psutil
import os
import pandas as pd

# 求解每列的最大最小
df = pd.read_csv('btc.csv')
min_df = df.min()
max_df = df.max()

# 查看内存占用情况
info = psutil.virtual_memory()
print(psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024, 'MB')
```

输出当前使用的内存为 455.03515625 MB

把求解最大最小过程封装成一个函数时

```python
import psutil
import os

# 封装函数
def get_min_max():
    import pandas as pd
    df = pd.read_csv('btc.csv')
    min_df = df.min()
    max_df = df.max()
    return min_df, max_df

# 求解每列的最大最小
min_df, max_df = get_min_max()

# 查看内存占用情况
info = psutil.virtual_memory()
print(psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024, 'MB')
```

输出当前使用的内存为 76.86328125 MB

以上过程中间变量 df 并不是我们所需要的，但在数据处理过程中会占用大量内存，由于 Python 的内存回收机制，在单步执行时即使用 del 命令删除某个中间变量，内存资源也无法释放，所以采用封装函数的方式是一种较好的方式。

##### 3. 使用迭代器或生成器读取数据

采用迭代器或生成器的方式读取数据时，并没有真正读取数据，而是在调用 next() ，get_chunk()等函数时才会获取加载真正的数据。这样我们就可以分块读取处理数据，减少一次性加载数据时内存占用过大的问题。

以下示例读取大型 csv 文件时，可以采用迭代器的方式加载，加载数据时基本不占用内存，只有在调用 get_chunk 函数时才会加载指定数量数据。

```python
import pandas as pd
reader = pd.read_csv('btc.csv', iterator=True)

# 通过 get_chunk 函数获取指定数量的数据
df = reader.get_chunk(1000)
```

##### 4. 其他减少内存占用的技巧

- 图片数据集读取时只存储图片名称的列表，在需要处理时再加载数据。
- 很多机器学习框架提供了控制内存占用的接口参数，例如，在 TensorFlow 中训练神经网络模型时可以控制 batch_size 的值，从而限制训练过程中的内存占用；在 Keras 中提供 fit_generator 函数，实现逐批次生成数据，按批次训练模型。

##### 总结

内存的减少是靠牺牲时间资源或 CPU 资源来换取的，实际使用时要综合权衡。在进行数据分析处理时良好的数据处理思维可以大幅提高我们分析数据的效率，减少不必要的资源浪费。











## 3．**模块**

拥有数据集之后，你就可以将它导入创建好的模块项目中进行分析和训练了。模块是可复用的算法组件，能够被引用在项目中。

#### （1）**模块的开发流程**

1. 创建模块（Create module project）

2. 导入数据集（Import datasets）

3. 分析数据（Analyze data）

4. 开发（Develop）

5. 训练 (Train)

6. 部署（Deploy）

## 4．**应用**

应用是由模块组成、有特定功能的软件程序，能够实现较复杂的功能。下面举两个简单的例子：

![](https://imgbed.momodel.cn/%E6%96%B0b%E7%AB%AF%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/wps/wps237.jpg) 

利用平台已有的公开数据集和模块，你可以简单快捷地创造出属于自己AI应用。接着只需要使用我们的部署功能，就能将自己的作品变成服务，供其他用户使用。

#### （1）**应用的开发流程**

1. 创建项目（Create app project）

2. 调用已有模块（Import modules）

3. 组装集成（Integrate）

4. 发布部署（Deploy）

5. 运行调用（Use）
